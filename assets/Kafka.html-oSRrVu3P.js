import{_ as s}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as n,a as e,o as i}from"./app-NomDibRt.js";const l="/vpress/images/spring/springboot/9-1.jpg",p={};function r(t,a){return i(),n("div",null,a[0]||(a[0]=[e('<h1 id="spring-boot-集成-kafka" tabindex="-1"><a class="header-anchor" href="#spring-boot-集成-kafka"><span>Spring Boot 集成 Kafka</span></a></h1><blockquote><p>作者：老马<br><br>公众号：老马啸西风<br><br> 博客：<a href="https://houbb.github.io/" target="_blank" rel="noopener noreferrer">https://houbb.github.io/</a><br><br> 人生理念：知行合一</p></blockquote><p><code>Spring Boot 作为主流微服务框架，拥有成熟的社区生态。市场应用广泛，为了方便大家，整理了一个基于spring boot的常用中间件快速集成入门系列手册，涉及RPC、缓存、消息队列、分库分表、注册中心、分布式配置等常用开源组件，大概有几十篇文章，陆续会开放出来，感兴趣同学可以关注&amp;收藏</code></p><p>消息通信有两种基本模型，即发布-订阅（Pub-Sub）模型和点对点（Point to Point）模型，发布-订阅支持生产者消费者之间的一对多关系，而点对点模型中有且仅有一个消费者。</p><h2 id="简介" tabindex="-1"><a class="header-anchor" href="#简介"><span>简介</span></a></h2><p>Kafka 是由Apache软件基金会开发的一个开源流处理平台，由Scala和Java编写。该项目的目标是为处理实时数据提供一个统一、高吞吐、低延迟的平台。其持久化层本质上是一个“按照分布式事务日志架构的大规模发布/订阅消息队列”。</p><p>Kafka 高效地处理实时流式数据，可以实现与Storm、HBase和Spark的集成。作为聚类部署到多台服务器上，Kafka处理它所有的发布和订阅消息系统使用了四个API，即生产者API、消费者API、Stream API和Connector API。它能够传递大规模流式消息，自带容错功能，已经取代了一些传统消息系统，如JMS、AMQP等。</p><h2 id="为什么使用-kafka" tabindex="-1"><a class="header-anchor" href="#为什么使用-kafka"><span>为什么使用 kafka</span></a></h2><ul><li>削峰填谷。缓冲上下游瞬时突发流量，保护 “脆弱” 的下游系统不被压垮，避免引发全链路服务 “雪崩”。</li><li>系统解耦。发送方和接收方的松耦合，一定程度简化了开发成本，减少了系统间不必要的直接依赖。</li><li>异步通信：消息队列允许用户把消息放入队列但不立即处理它。</li><li>可恢复性：即使一个处理消息的进程挂掉，加入队列中的消息仍然可以在系统恢复后被处理。</li></ul><h2 id="业务场景" tabindex="-1"><a class="header-anchor" href="#业务场景"><span>业务场景</span></a></h2><ul><li>一些同步业务流程的非核心逻辑，对时间要求不是特别高，可以解耦异步来执行</li><li>系统日志收集，采集并同步到kafka，一般采用ELK组合玩法</li><li>一些大数据平台，用于各个系统间数据传递</li></ul><h2 id="基本架构" tabindex="-1"><a class="header-anchor" href="#基本架构"><span>基本架构</span></a></h2><p>Kafka 运行在一个由一台或多台服务器组成的集群上，并且分区可以跨集群节点分布</p><div align="left"><img src="'+l+`" width="700px"></div><p>1、Producer 生产消息，发送到Broker中</p><p>2、Leader状态的Broker接收消息，写入到相应topic中。在一个分区内，这些消息被索引并连同时间戳存储在一起</p><p>3、Leader状态的Broker接收完毕以后，传给Follow状态的Broker作为副本备份</p><p>4、 Consumer 消费者的进程可以从分区订阅，并消费消息</p><h2 id="常用术语" tabindex="-1"><a class="header-anchor" href="#常用术语"><span>常用术语</span></a></h2><ul><li>Broker。负责接收和处理客户端发送过来的请求，以及对消息进行持久化。虽然多个 Broker 进程能够运行在同一台机器上，但更常见的做法是将不同的 Broker 分散运行在不同的机器上</li><li>主题：Topic。主题是承载消息的逻辑容器，在实际使用中多用来区分具体的业务。</li><li>分区：Partition。一个有序不变的消息序列。每个主题下可以有多个分区。</li><li>消息：这里的消息就是指 Kafka 处理的主要对象。</li><li>消息位移：Offset。表示分区中每条消息的位置信息，是一个单调递增且不变的值。</li><li>副本：Replica。Kafka 中同一条消息能够被拷贝到多个地方以提供数据冗余，这些地方就是所谓的副本。副本还分为领导者副本和追随者副本，各自有不同的角色划分。每个分区可配置多个副本实现高可用。一个分区的N个副本一定在N个不同的Broker上。</li><li>Leader：每个分区多个副本的“主”副本，生产者发送数据的对象，以及消费者消费数据的对象，都是 Leader。</li><li>Follower：每个分区多个副本的“从”副本，实时从 Leader 中同步数据，保持和 Leader 数据的同步。Leader 发生故障时，某个 Follower 还会成为新的 Leader。</li><li>生产者：Producer。向主题发布新消息的应用程序。</li><li>消费者：Consumer。从主题订阅新消息的应用程序。</li><li>消费者位移：Consumer Offset。表示消费者消费进度，每个消费者都有自己的消费者位移。offset保存在broker端的内部topic中，不是在clients中保存</li><li>消费者组：Consumer Group。多个消费者实例共同组成的一个组，同时消费多个分区以实现高吞吐。</li><li>重平衡：Rebalance。消费者组内某个消费者实例挂掉后，其他消费者实例自动重新分配订阅主题分区的过程。Rebalance 是 Kafka 消费者端实现高可用的重要手段。</li></ul><h2 id="代码演示" tabindex="-1"><a class="header-anchor" href="#代码演示"><span>代码演示</span></a></h2><h3 id="外部依赖" tabindex="-1"><a class="header-anchor" href="#外部依赖"><span>外部依赖</span></a></h3><p>在 <code>pom.xml</code> 中添加 Kafka 依赖</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>&lt;dependency&gt;</span></span>
<span class="line"><span>    &lt;groupId&gt;org.springframework.kafka&lt;/groupId&gt;</span></span>
<span class="line"><span>    &lt;artifactId&gt;spring-kafka&lt;/artifactId&gt;</span></span>
<span class="line"><span>&lt;/dependency&gt;</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><blockquote><p>由于spring-boot-starter-parent 指定的版本号是 2.1.5.RELEASE，Spring boot 会对外部框架的版本号统一管理，spring-kafka 引入的版本是 2.2.6.RELEASE</p></blockquote><h3 id="配置文件" tabindex="-1"><a class="header-anchor" href="#配置文件"><span>配置文件</span></a></h3><p>在配置文件 <code>application.yaml</code> 中配置 Kafka 的相关参数，具体内容如下：</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>Spring:</span></span>
<span class="line"><span>  kafka:</span></span>
<span class="line"><span>    bootstrap-servers: localhost:9092</span></span>
<span class="line"><span>    producer:</span></span>
<span class="line"><span>      retries: 3  # 生产者发送失败时，重试次数</span></span>
<span class="line"><span>      batch-size: 16384</span></span>
<span class="line"><span>      buffer-memory: 33554432</span></span>
<span class="line"><span>      key-serializer: org.apache.kafka.common.serialization.StringSerializer # 生产者消息key和消息value的序列化处理类</span></span>
<span class="line"><span>      value-serializer: org.apache.kafka.common.serialization.StringSerializer</span></span>
<span class="line"><span>    consumer:</span></span>
<span class="line"><span>      group-id: tomge-consumer-group  # 默认消费者group id</span></span>
<span class="line"><span>      auto-offset-reset: earliest</span></span>
<span class="line"><span>      enable-auto-commit: true</span></span>
<span class="line"><span>      auto-commit-interval: 100</span></span>
<span class="line"><span>      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer</span></span>
<span class="line"><span>      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>对应的配置类 <code>org.springframework.boot.autoconfigure.kafka.KafkaProperties</code>，来初始化kafka相关的bean实例对象，并注册到spring容器中。</p><h3 id="发送消息" tabindex="-1"><a class="header-anchor" href="#发送消息"><span>发送消息</span></a></h3><p>Spring Boot 作为一款支持快速开发的集成性框架，同样提供了一批以 <code>-Template</code> 命名的模板工具类用于实现消息通信。对于 Kafka 而言，这个工具类就是<code>KafkaTemplate</code>。</p><p>KafkaTemplate 提供了一系列 send 方法用来发送消息，典型的 send 方法定义如下代码所示：</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>public ListenableFuture&lt;SendResult&lt;K, V&gt;&gt; send(String topic, @Nullable V data) {</span></span>
<span class="line"><span> 。。。。 省略</span></span>
<span class="line"><span>}</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>生产端提供了一个restful接口，模拟发送一条创建新用户消息。</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>@GetMapping(&quot;/add_user&quot;)</span></span>
<span class="line"><span>public Object add() {</span></span>
<span class="line"><span>    try {</span></span>
<span class="line"><span>        Long id = Long.valueOf(new Random().nextInt(1000));</span></span>
<span class="line"><span>        User user = User.builder().id(id).userName(&quot;TomGE&quot;).age(29).address(&quot;上海&quot;).build();</span></span>
<span class="line"><span>        ListenableFuture&lt;SendResult&gt; listenableFuture = kafkaTemplate.send(addUserTopic, JSON.toJSONString(user));</span></span>
<span class="line"><span>        </span></span>
<span class="line"><span>        // 提供回调方法，可以监控消息的成功或失败的后续处理</span></span>
<span class="line"><span>        listenableFuture.addCallback(new ListenableFutureCallback&lt;SendResult&gt;() {</span></span>
<span class="line"><span>            @Override</span></span>
<span class="line"><span>            public void onFailure(Throwable throwable) {</span></span>
<span class="line"><span>                System.out.println(&quot;发送消息失败，&quot; + throwable.getMessage());</span></span>
<span class="line"><span>            }</span></span>
<span class="line"><span></span></span>
<span class="line"><span>            @Override</span></span>
<span class="line"><span>            public void onSuccess(SendResult sendResult) {</span></span>
<span class="line"><span>                // 消息发送到的topic</span></span>
<span class="line"><span>                String topic = sendResult.getRecordMetadata().topic();</span></span>
<span class="line"><span>                // 消息发送到的分区</span></span>
<span class="line"><span>                int partition = sendResult.getRecordMetadata().partition();</span></span>
<span class="line"><span>                // 消息在分区内的offset</span></span>
<span class="line"><span>                long offset = sendResult.getRecordMetadata().offset();</span></span>
<span class="line"><span>                System.out.println(String.format(&quot;发送消息成功，topc：%s, partition: %s, offset：%s &quot;, topic, partition, offset));</span></span>
<span class="line"><span>            }</span></span>
<span class="line"><span>        });</span></span>
<span class="line"><span>        return &quot;消息发送成功&quot;;</span></span>
<span class="line"><span>    } catch (Exception e) {</span></span>
<span class="line"><span>        e.printStackTrace();</span></span>
<span class="line"><span>        return &quot;消息发送失败&quot;;</span></span>
<span class="line"><span>    }</span></span>
<span class="line"><span>}</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><blockquote><p>实际上开发使用的Kafka默认允许自动创建Topic，创建Topic时默认的分区数量是1，可以通过server.properties文件中的num.partitions=1修改默认分区数量。在生产环境中通常会关闭自动创建功能，Topic需要由运维人员先创建好。</p></blockquote><h3 id="消费消息" tabindex="-1"><a class="header-anchor" href="#消费消息"><span>消费消息</span></a></h3><p>在 Kafka 中消息通过服务器推送给各个消费者，而 Kafka 的消费者在消费消息时，需要提供一个监听器（Listener）对某个 Topic 实现监听，从而获取消息，这也是 Kafka 消费消息的唯一方式。</p><p>定义一个消费类，在处理具体消息业务逻辑的方法上添加 <code>@KafkaListener</code> 注解，并配置要消费的topic，代码如下所示：</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>@Component</span></span>
<span class="line"><span>public class UserConsumer {</span></span>
<span class="line"><span></span></span>
<span class="line"><span>    @KafkaListener(topics = &quot;add_user&quot;)</span></span>
<span class="line"><span>    public void receiveMesage(String content) {</span></span>
<span class="line"><span>        System.out.println(&quot;消费消息：&quot; + content);</span></span>
<span class="line"><span>    }</span></span>
<span class="line"><span>}</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><blockquote><p>是不是很简单，添加kafka依赖、使用KafkaTemplate、@KafkaListener注解就完成消息的生产和消费，其实是SpringBoot在背后默默的做了很多工作，如果感兴趣可以研究下<code>spring-boot-autoconfigure</code> ，里面提供了常用开源框架的客户端实例封装。</p></blockquote><h2 id="项目源码" tabindex="-1"><a class="header-anchor" href="#项目源码"><span>项目源码</span></a></h2><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>https://github.com/aalansehaiyang/spring-boot-bulking  </span></span>
<span class="line"><span></span></span>
<span class="line"><span>模块：spring-boot-bulking-kafka</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="参考资料" tabindex="-1"><a class="header-anchor" href="#参考资料"><span>参考资料</span></a></h2><ul><li><a href="https://blog.csdn.net/yuanlong122716/article/details/105160545/" target="_blank" rel="noopener noreferrer">https://blog.csdn.net/yuanlong122716/article/details/105160545/</a></li></ul>`,45)]))}const c=s(p,[["render",r]]),u=JSON.parse('{"path":"/posts/interview/spring/springboot/Kafka.html","title":"Spring Boot 集成 Kafka","lang":"zh-CN","frontmatter":{"title":"Spring Boot 集成 Kafka","description":"Spring Boot 集成 Kafka 作者：老马 公众号：老马啸西风 博客：https://houbb.github.io/ 人生理念：知行合一 Spring Boot 作为主流微服务框架，拥有成熟的社区生态。市场应用广泛，为了方便大家，整理了一个基于spring boot的常用中间件快速集成入门系列手册，涉及RPC、缓存、消息队列、分库分表、注册...","head":[["meta",{"property":"og:url","content":"https://houbb.github.io/vpress/posts/interview/spring/springboot/Kafka.html"}],["meta",{"property":"og:site_name","content":"老马啸西风"}],["meta",{"property":"og:title","content":"Spring Boot 集成 Kafka"}],["meta",{"property":"og:description","content":"Spring Boot 集成 Kafka 作者：老马 公众号：老马啸西风 博客：https://houbb.github.io/ 人生理念：知行合一 Spring Boot 作为主流微服务框架，拥有成熟的社区生态。市场应用广泛，为了方便大家，整理了一个基于spring boot的常用中间件快速集成入门系列手册，涉及RPC、缓存、消息队列、分库分表、注册..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-03-30T09:38:40.000Z"}],["meta",{"property":"article:modified_time","content":"2025-03-30T09:38:40.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"Spring Boot 集成 Kafka\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2025-03-30T09:38:40.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"老马啸西风\\",\\"url\\":\\"https://houbb.github.io\\"}]}"]]},"git":{"createdTime":1743327520000,"updatedTime":1743327520000,"contributors":[{"name":"houbb","username":"houbb","email":"houbinbin.echo@gmail.com","commits":1,"url":"https://github.com/houbb"}]},"readingTime":{"minutes":7.05,"words":2115},"filePathRelative":"posts/interview/spring/springboot/Kafka.md","localizedDate":"2025年3月30日","excerpt":"\\n<blockquote>\\n<p>作者：老马<br>\\n<br>公众号：老马啸西风<br>\\n<br> 博客：<a href=\\"https://houbb.github.io/\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">https://houbb.github.io/</a><br>\\n<br> 人生理念：知行合一</p>\\n</blockquote>\\n<p><code>Spring Boot 作为主流微服务框架，拥有成熟的社区生态。市场应用广泛，为了方便大家，整理了一个基于spring boot的常用中间件快速集成入门系列手册，涉及RPC、缓存、消息队列、分库分表、注册中心、分布式配置等常用开源组件，大概有几十篇文章，陆续会开放出来，感兴趣同学可以关注&amp;收藏</code></p>","autoDesc":true}');export{c as comp,u as data};
