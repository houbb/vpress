import{_ as i}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as t,a as e,o}from"./app-NomDibRt.js";const p="/vpress/images/arch/system/2-1.jpg",r={};function n(a,l){return o(),t("div",null,l[0]||(l[0]=[e('<h1 id="海量数据业务有哪些优化手段" tabindex="-1"><a class="header-anchor" href="#海量数据业务有哪些优化手段"><span>海量数据业务有哪些优化手段？</span></a></h1><blockquote><p>作者：老马<br><br>公众号：老马啸西风<br><br> 博客：<a href="https://houbb.github.io/" target="_blank" rel="noopener noreferrer">https://houbb.github.io/</a><br><br> 人生理念：知行合一</p></blockquote><p>互联网时代，亿级用户各种网络行为产生大量数据，如何解决海量数据存储？如何高性能读写？解决思路有哪些，本文列举了常用的解决方案：</p><ul><li>缓存加速</li><li>读写分离</li><li>垂直拆分</li><li>分库分表</li><li>冷热数据分离</li><li>ES助力复杂搜索</li><li>NoSQL</li><li>NewSQL</li></ul><h2 id="🌴-缓存加速" tabindex="-1"><a class="header-anchor" href="#🌴-缓存加速"><span>🌴 缓存加速</span></a></h2><p>缓存就是为了弥补存储系统在这些复杂业务场景下的不足，其基本原理是将可能重复使用的数据放到内存中，一次生成、多次使用，避免每次使用都去访问存储系统。</p><p>缓存能够带来性能的大幅提升，以 Memcache 为例，单台 Memcache 服务器简单的 key-value 查询能够达到 TPS 50000 以上；Redis性能数据是10W+ QPS</p><p>为什么缓存的速度那么快？</p><div align="left"><img src="'+p+'" width="650px"></div><p>从上图中发现，同机房两台服务器跑个来回，再从内存中顺序读取1M数据，共耗时0.75ms。如果从硬盘读取，做一次磁盘寻址需要10ms，再从磁盘里顺序读取1M数据需要30ms。可见，使用内存缓存性能上提高多个数量级，同时也能支持更高的并发量。</p><p><strong>常见的缓存分为本地缓存和分布式缓存，区别在与是否要走网络通讯。</strong></p><p>本地缓存是部署在应用服务器中，而我们应用服务器通常会部署多台，当数据更新时，我们不能确定哪台服务器本地中了缓存，更新或者删除所有服务器的缓存不是一个好的选择，所以我们通常会等待缓存过期。因此，这种缓存的有效期很短，通常为分钟或者秒级别，以避免返回前端脏数据。</p><p>相反，分布式缓存采用集群化管理，支持水平扩容，并提供客户端路由数据，数据一致性维护更好。虽然有不到 1ms的网络开销，但比起其优势，这点损耗微不足道。</p><blockquote><p>注意： 在引入缓存后，如果数据库的访问量依旧很大，我们可以考虑对数据库读写分离，通过多个读库分摊压力。</p></blockquote><h2 id="🌴-读写分离" tabindex="-1"><a class="header-anchor" href="#🌴-读写分离"><span>🌴 读写分离</span></a></h2><p>互联网业务有个重要特性，不知道大家有没有发现？大多数业务都是读多写少，如：刷朋友圈的请求量肯定比发朋友圈的量大，淘宝上一个商品的浏览量也肯定远大于它的下单量。</p><p>那么数据库如何抵抗更高的查询请求？那么首先你需要把读写流量区分开，因为这样才方便针对读流量做单独的扩展，这就是我们所说的主从读写分离。</p><p><strong>读写分离定义</strong></p><blockquote><p>每次写数据时会同步多份到其它的存储系统，生成多个备份，当用户读取数据时直接从备份存储系统获取数据。</p></blockquote><p><strong>应用场景：</strong></p><ul><li>读多写少</li><li>数据量较大</li><li>数据查询频率很高，且对性能要求很高</li></ul><p><strong>实现思路：</strong></p><p>1、由于数据存在备份，甚至是多份备份。那么如何来实现数据备份？</p><ul><li>直接方式是修改业务代码，这也是新手常用的方式。在写入主库后，同步更新备库。</li></ul><blockquote><p>缺点：如果备库较多，会同步调用多次，如果备库做了调整，业务代码也要跟着修改。优点：实时性好，所见即所得。</p></blockquote><ul><li>监控数据库 binlog 日志，（如：引入canal组件），由数据同步中心，将变更数据同步到备库中。该方式实现了业务代码解耦，扩展性较好，也是实际工作推崇的技术方案。</li></ul><blockquote><p>缺点：数据同步需要花费一定时间，如果这期间查询备库，查询到的是旧数据，此类业务场景需要特别注意。</p></blockquote><p>2、数据备份有哪些存储介质？</p><ul><li>mysql。关系型数据库，容易上手</li><li>Elasticsearch。可以定制索引结构，满足多样化复杂的业务查询。另外采用分片结构，可以满足较大量数据存储。</li><li>MongoDB</li><li>HBase</li></ul><blockquote><p>市面的开源框架较多，要注意技术选型。</p></blockquote><p>3、查询数据如何实现？</p><p>这个没有什么可以讲得，以上的中间件开源社区都有封装好的API，直接调用即可。但要注意一点。<code>数据查询时，如果还没有备份完成怎么办？</code></p><ul><li>一种方案，不允许用户查询，用户体验较差，也不容易控制。鬼知道有没有同步完。</li><li>对实时性要求不高的查询，选择走备库，但页面要做好提示引导。比如<code>付款动作</code>，一般会有一个中间页，提示用户付款成功。一般不会直接跳到订单详情页。</li><li>对实时性要求非常高的查询，走主库。比如：新用户注册，立即登录。</li></ul><h2 id="🌴-垂直拆分" tabindex="-1"><a class="header-anchor" href="#🌴-垂直拆分"><span>🌴 垂直拆分</span></a></h2><p>垂直拆分是指按照业务功能拆分，业务表分布在不同的数据库上，这样也就将数据或者说压力分担到不同的库上面 。比如电商系统会拆分出会员、商品、交易、类目、营销、搜索等业务库，分别归属到不用的技术团队维护。</p><p><strong>优势：</strong></p><ul><li>职责单一，业务清晰</li><li>便于维护，易扩展</li><li>通常会独立部署，独享服务器资源，数据库访问性能会有很大提升</li><li>耦合性低，降低不同应用间故障干扰</li></ul><p><strong>缺点：</strong></p><ul><li>形成跨库事务，需要引入<strong>分布式事务解决方案</strong>，提高整个应用的复杂度。</li><li>“木桶效应”，任何一个短板有可能影响整个系统</li><li>不用业务表之间不能 <code>join</code> ，只能通过服务间接口调用，在应用层做数据组装，提高了复杂度</li></ul><h2 id="🌴-分库分表" tabindex="-1"><a class="header-anchor" href="#🌴-分库分表"><span>🌴 分库分表</span></a></h2><p>注意：数据库垂直拆分后，遇到单机数据库性能瓶颈，我们可以考虑分表。</p><p>分表又可以细分为 <strong>垂直分表</strong> 和 <strong>水平分表</strong> 两种形式。</p><h3 id="_1、垂直分表" tabindex="-1"><a class="header-anchor" href="#_1、垂直分表"><span>1、垂直分表</span></a></h3><p>数据表垂直拆分就是纵向地把一张表中的列拆分到多个表，<strong>表由“宽”变“窄”</strong>，简单来讲，就是将大表拆成多张小表，一般会遵循以下几个原则：</p><ul><li>冷热分离，把常用的列放在一个表，不常用的放在一个表。</li><li>字段更新、查询频次拆分</li><li>大字段列独立存放</li><li>关系紧密的列放在一起</li></ul><h3 id="_2、水平分表" tabindex="-1"><a class="header-anchor" href="#_2、水平分表"><span>2、水平分表</span></a></h3><p>表结构维持不变，对数据行进行切分，将表中的某些行切分到一张表中，而另外的某些行又切分到其他的表中，也就是说拆分后数据集的并集等于拆分前的数据集。</p><p><strong>分库分表技术点：</strong></p><ul><li>SQl组合。因为是逻辑表名，需要按分表键计算对应的物理表编号，根据逻辑重新组装动态的SQL</li><li>数据库路由。如果采用分库，需要根据逻辑的分表编号计算数据库的编号</li><li>结果合并。如果查询没有传入指定的分表键，会全库执行，此时需要将结果合并再输出。</li></ul><p><strong>目前市面有很多的开源框架，大致分为两种模式：</strong></p><ul><li><p>Proxy模式。SQL 组合、数据库路由、执行结果合并等功能全部存放在一个代理服务中，业务方可以当做。</p><ul><li>优点：支持多种语言。升级方便。对业务代码无侵入。</li><li>缺点：额外引入一个中间件，容易形成流量瓶颈，安全风险较高，有运维成本</li></ul></li><li><p>Client 模式。常见是 <code>sharding-jdbc</code>，业务端系统只需要引入一个jar包即可，按照规范配置路由规则。jar 中处理 SQL 组合、数据库路由、执行结果合并等相关功能。</p><ul><li>优点：简单、轻便。不存在流量瓶颈，减少运维成本</li><li>缺点：单语言，升级不方便。</li></ul></li></ul><p><strong>实现思路：</strong></p><p>1、如何选择分表键。</p><p>数据尽量均匀分布在不同表或库、跨库查询操作尽可能少、这个字段的值不会变。比如电商订单采用user_id。</p><p>2、分片策略。</p><p>根据范围分片、根据 hash 值分片、根据 hash 值及范围混合分片</p><p>3、如何编写业务代码。结合具体的业务实现。</p><p>4、历史数据迁移</p><ul><li>增量数据监听 binlog，然后通过 canal 通知迁移程序开始增量数据迁移</li><li>开启任务，全量数据迁移</li><li>开启双写，并关闭增量迁移任务</li><li>读业务切换到新库</li><li>线上运行一段时间，确认没有问题后，下线老库的写操作</li></ul><blockquote><p><strong>有一种说法：数据量大，就分表；并发高，就分库</strong></p></blockquote><p>最后：在实际的业务开发中，要做好数据量的增长预测，做好技术方案选型。另外，在引入分表方案后，要考虑数据倾斜问题，这个跟分表键有很大关系，避免数据分布不均衡影响系统性能。</p><h2 id="🌴-冷热数据分离" tabindex="-1"><a class="header-anchor" href="#🌴-冷热数据分离"><span>🌴 冷热数据分离</span></a></h2><p>根据<strong>二八定律</strong>，系统绝大部分的性能开销花在20%的业务。数据也不例外，从数据的使用频率来看，经常被业务访问的数据称为热点数据；反之，称之为冷数据。</p><p>在了解的数据的冷、热特性后，便可以指导我们做一些有针对性的性能优化。这里面有业务层面的优化，也有技术层面的优化。比如：电商网站，一般只能查询3个月内的订单，如果你想看看3个月前的订单，需要访问历史订单页面。</p><p><strong>实现思路：</strong></p><p>1、冷热数据区分的标准是什么？要结合业务思考，可能要找产品同学一块讨论才能做决策，切记不要拍脑袋。以电商订单为例：</p><ul><li>方案一：以“下单时间”为标准，将3 个月前的订单数据当作冷数据，3 个月内的当作热数据。</li><li>方案二：根据“订单状态”字段来区分，已完结的订单当作冷数据，未完结的订单当作热数据。</li><li>方案三：组合方式，把下单时间 &gt; 3 个月且状态为“已完结”的订单标识为冷数据，其他的当作热数据。</li></ul><p>2、如何触发冷热数据的分离</p><ul><li>方案一：直接修改业务代码，每次业务请求触发冷热数据判断，根据结果路由到对应的冷数据表或热数据表。缺点：如果判断标准是 <code>时间维度</code>，数据过期了无法主动感知。</li><li>方案二：如果觉得修改业务代码，耦合性高，不易于后期维护。可以通过监听数据库变更日志 binlog 方式来触发</li><li>方案三：常用的手段是跑定时任务，一般是选择凌晨系统压力小的时候，通过跑批任务，将满足条件的冷数据迁移到其他存储介质。在途业务表中只留下来少量的热点数据。</li></ul><p>3、如何实现冷热数据分离，过程大概分为三步：</p><ul><li>判断数据是冷、还是热</li><li>将冷数据插入冷数据表中</li><li>然后，从原来的热库中删除迁移的数据</li></ul><p>4、如何使用冷热数据</p><ul><li>方案一：界面设计时会有选项区分，如上面举例的电商订单</li><li>方案二：直接在业务代码里区分。</li></ul><h2 id="🌴-es助力复杂搜索" tabindex="-1"><a class="header-anchor" href="#🌴-es助力复杂搜索"><span>🌴 ES助力复杂搜索</span></a></h2><p>ES是基于索引结构，无法像mysql那样使用join语句。所以我们在构建索引时需要将主表记录及关联表打平，整合到一条记录中。以<strong>倒排索引</strong>作为核心技术原理，为你提供了分布式的全文搜索服务。</p><p>mysql与es的概念关系映射</p><table><thead><tr><th>mysql</th><th>ES</th></tr></thead><tbody><tr><td>数据库</td><td>索引 index</td></tr><tr><td>表</td><td>Type</td></tr><tr><td>行</td><td>Document</td></tr><tr><td>列</td><td>Field</td></tr></tbody></table><p><strong>ES分页查询流程：</strong></p><ul><li>协调节点首先把分页查询请求分发给所有分片</li><li>每个分片在本地查询一个结果集列表（包含 Document id和搜索分数），返回（from+size）条记录。<code>特别注意：这一步返回的只是主键id</code></li><li>协调节点拿到所有分片的返回数据，按分数全局排序，并截取一页大小的数据</li><li>协调节点根据结果集里的Document id 向所有的分片查询完整的Document，然后协调节点将结果返回给客户端。</li></ul><p>在读取操作流程中，Elasticsearch 集群实际上需要给协调节点返回 shards number * （from + size) 条数据，然后在单机上进行排序，最后返回给客户端这个 size 大小的数据。</p><p>随着分页的深度增加，性能会越来越差，为了避免这个问题，ES有个<code>max_result_window</code>配置，默认值10000，超过这个大小，ES返回错误。</p><p>如果用户确实有深度翻页的需求，可以采用<code>search_after</code>解决，比如 <code>id&gt;20000 limit 10</code>。<strong>缺点：无法实现跳页。</strong></p><h2 id="🌴-nosql" tabindex="-1"><a class="header-anchor" href="#🌴-nosql"><span>🌴 NoSQL</span></a></h2><p>NoSQL 数据库放弃了与分布式环境相悖的 <strong>ACID 事务</strong>，提供了另一种聚合数据模型，从而具有可伸缩性的非关系数据库。</p><p><strong>NoSQL 数据库分为五类：</strong></p><p>1、KV 数据库，通常基于哈希表实现，性能非常好。其中 Value 的类型通常由应用层代码决定。常用的如 Redis，value支持 String、List、Map、Set、Zset等<strong>复合结构</strong>。</p><p>2、文档型数据库，如：MongoDB、CouchDB ，这种数据库的特点是 Schema Free（模式自由），数据表中的字段可以任意扩展，比如说电商系统中的商品有非常多的字段，并且不同品类的商品的字段也都不尽相同，使用关系型数据库就需要不断增加字段支持，而用文档型数据库就简单很多了。</p><p>3、列式数据库，比如 Hbase、Cassandra。列式数据库基于 Key 来映射行，再通过列名进行二级映射，同时它基于列来安排存储的拓扑结构，这样当仅读写大量行中某个列时，操作的数据节点、磁盘非常集中，磁盘 IO、网络 IO 都会少很多。列式数据库的应用场景非常有针对性，比如博客文章标签的行数很多，但在做数据分析时往往只读取标签列，这就很适合使用列式数据库。再比如，通过倒排索引实现了全文检索的 ElasticSearch，就适合使用列式存储存放 Doc Values，这样做排序、聚合时非常高效。</p><p>4、图数据库，在社交关系、知识图谱等场景中，携带各种属性的边可以表示节点间的关系，由于节点的关系数量多，而且非常容易变化，所以关系数据库的实现成本很高，而图数据库既没有固定的数据模型，遍历关系的速度也非常快，很适合处理这类问题。</p><p>5、时序数据库，如：InfluxDB，一般用来做 <code>Metrics</code> 打点。时序数据库的优势，在于处理指标数据的聚合，并且读写效率非常高。</p><blockquote><p>应用场景：比如对1000 万数据进行一个统计，查询最近 60 天的数据，按照 1 小时的时间粒度聚合，统计 value 列的最大值、最小值和平均值，并将统计结果绘制成曲线图。</p></blockquote><p>InfluxDB 也有不足之处：</p><ul><li>InfluxDB 不支持数据更新操作，毕竟时间数据只能随着时间产生新数据，肯定无法对过去的数据做修改；</li><li>从数据结构上说，时间序列数据数据没有单一的主键标识，必须包含时间戳，数据只能和时间戳进行关联，不适合普通业务。</li></ul><p><strong>相比传统关系型数据库，NoSQL 有哪些优势：</strong></p><ul><li>弥补了传统数据库在性能方面的不足；</li><li>数据库变更方便，不需要更改原先的数据结构；</li><li>适合互联网常见的大数据量的场景；</li></ul><h2 id="🌴-newsql" tabindex="-1"><a class="header-anchor" href="#🌴-newsql"><span>🌴 NewSQL</span></a></h2><p>New SQL 是新一代的分布式数据库，它具备原生分布式存储系统高性能、高可靠、高可用和弹性扩容的能力，同时还兼顾了传统关系型数据库的 SQL 支持。另外，它还提供了和传统关系型数据库不相上下的、真正的事务支持，具备了支撑在线交易类业务的能力。</p><p>优点：</p><ul><li>完整地支持 SQL 和 ACID 事务，提供和 Old SQL 隔离级别相当的事务能力；</li><li>高性能、高可靠、高可用，支持水平扩容。</li></ul><p>常见的 New SQL 数据库有：Google 的 Cloud Spanner、阿里巴巴的 OceanBase 以及开源的CockroachDB。</p>',100)]))}const h=i(r,[["render",n]]),d=JSON.parse('{"path":"/posts/interview/arch/system/%E6%B5%B7%E9%87%8F%E6%95%B0%E6%8D%AE%E4%B8%9A%E5%8A%A1%E6%9C%89%E5%93%AA%E4%BA%9B%E4%BC%98%E5%8C%96%E6%89%8B%E6%AE%B5%EF%BC%9F.html","title":"海量数据业务有哪些优化手段？","lang":"zh-CN","frontmatter":{"title":"海量数据业务有哪些优化手段？","description":"海量数据业务有哪些优化手段？ 作者：老马 公众号：老马啸西风 博客：https://houbb.github.io/ 人生理念：知行合一 互联网时代，亿级用户各种网络行为产生大量数据，如何解决海量数据存储？如何高性能读写？解决思路有哪些，本文列举了常用的解决方案： 缓存加速 读写分离 垂直拆分 分库分表 冷热数据分离 ES助力复杂搜索 NoSQL Ne...","head":[["meta",{"property":"og:url","content":"https://houbb.github.io/vpress/posts/interview/arch/system/%E6%B5%B7%E9%87%8F%E6%95%B0%E6%8D%AE%E4%B8%9A%E5%8A%A1%E6%9C%89%E5%93%AA%E4%BA%9B%E4%BC%98%E5%8C%96%E6%89%8B%E6%AE%B5%EF%BC%9F.html"}],["meta",{"property":"og:site_name","content":"老马啸西风"}],["meta",{"property":"og:title","content":"海量数据业务有哪些优化手段？"}],["meta",{"property":"og:description","content":"海量数据业务有哪些优化手段？ 作者：老马 公众号：老马啸西风 博客：https://houbb.github.io/ 人生理念：知行合一 互联网时代，亿级用户各种网络行为产生大量数据，如何解决海量数据存储？如何高性能读写？解决思路有哪些，本文列举了常用的解决方案： 缓存加速 读写分离 垂直拆分 分库分表 冷热数据分离 ES助力复杂搜索 NoSQL Ne..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-03-30T09:38:40.000Z"}],["meta",{"property":"article:modified_time","content":"2025-03-30T09:38:40.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"海量数据业务有哪些优化手段？\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2025-03-30T09:38:40.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"老马啸西风\\",\\"url\\":\\"https://houbb.github.io\\"}]}"]]},"git":{"createdTime":1743327520000,"updatedTime":1743327520000,"contributors":[{"name":"houbb","username":"houbb","email":"houbinbin.echo@gmail.com","commits":1,"url":"https://github.com/houbb"}]},"readingTime":{"minutes":14.53,"words":4358},"filePathRelative":"posts/interview/arch/system/海量数据业务有哪些优化手段？.md","localizedDate":"2025年3月30日","excerpt":"\\n<blockquote>\\n<p>作者：老马<br>\\n<br>公众号：老马啸西风<br>\\n<br> 博客：<a href=\\"https://houbb.github.io/\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">https://houbb.github.io/</a><br>\\n<br> 人生理念：知行合一</p>\\n</blockquote>\\n<p>互联网时代，亿级用户各种网络行为产生大量数据，如何解决海量数据存储？如何高性能读写？解决思路有哪些，本文列举了常用的解决方案：</p>\\n<ul>\\n<li>缓存加速</li>\\n<li>读写分离</li>\\n<li>垂直拆分</li>\\n<li>分库分表</li>\\n<li>冷热数据分离</li>\\n<li>ES助力复杂搜索</li>\\n<li>NoSQL</li>\\n<li>NewSQL</li>\\n</ul>","autoDesc":true}');export{h as comp,d as data};
